{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \n",
    "        '''The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.'''\n",
    "\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        #print(self.weights)\n",
    "        # helper variables\n",
    "        self.bias_nitem = sum(sizes[1:])\n",
    "        self.weight_nitem = sum([self.weights[i].size for i in range(self.num_layers-2)])\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        '''Return the output of the network if ``a`` is input.'''\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = self.sigmoid(np.dot(w,a)+b)\n",
    "        return a\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        '''The sigmoid function.'''\n",
    "        return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "    def score(self, X, y):\n",
    "\n",
    "        '''\n",
    "        @X = data to test\n",
    "        @y = data-label to test\n",
    "        @returns = score of network prediction (less is better)\n",
    "        @ref: https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications\n",
    "        '''\n",
    "\n",
    "        total_score=0\n",
    "        for i in range(X.shape[0]):\n",
    "            predicted = self.feedforward(X[i].reshape(-1,1))\n",
    "            actual = y[i].reshape(-1,1)\n",
    "            total_score += np.sum(np.power(predicted-actual,2)/2)  # mean-squared error\n",
    "        return total_score\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "\n",
    "        '''\n",
    "        @X = data to test\n",
    "        @y = data-label to test\n",
    "        @returns = accuracy (%) (more is better)\n",
    "        '''\n",
    "\n",
    "        accuracy = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            output = self.feedforward(X[i].reshape(-1,1))\n",
    "            accuracy += int(np.argmax(output) == np.argmax(y[i]))\n",
    "        return accuracy / X.shape[0] * 100\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"\\nBias:\\n\\n\" + str(self.biases)\n",
    "        s += \"\\nWeights:\\n\\n\" + str(self.weights)\n",
    "        s += \"\\n\\n\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNGeneticAlgo:\n",
    "\n",
    "    def __init__(self, n_pops, net_size, mutation_rate, crossover_rate, retain_rate, X, y):\n",
    "\n",
    "        '''\n",
    "        n_pops   = How much population do our GA need to create\n",
    "        net_size = Size of neural network for population members\n",
    "        mutation_rate = probability of mutating all bias & weight inside our network\n",
    "        crossover_rate = probability of cross-overing all bias & weight inside out network\n",
    "        retain_rate = How many to retain our population for the best ones\n",
    "        X = our data to test accuracy\n",
    "        y = our data-label to test accuracy\n",
    "        '''\n",
    "\n",
    "        self.n_pops = n_pops\n",
    "        self.net_size = net_size\n",
    "        self.nets = [Network(self.net_size) for i in range(self.n_pops)]\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.crossover_rate = crossover_rate\n",
    "        self.retain_rate = retain_rate\n",
    "        self.X = X[:]\n",
    "        self.y = y[:]\n",
    "    \n",
    "    def get_random_point(self, type):\n",
    "\n",
    "        '''\n",
    "        @type = either 'weight' or 'bias'\n",
    "        @returns tuple (layer_index, point_index)\n",
    "            note: if type is set to 'weight', point_index will return (row_index, col_index)\n",
    "        '''\n",
    "\n",
    "        nn = self.nets[0]\n",
    "        layer_index, point_index = random.randint(0, nn.num_layers-2), 0\n",
    "        if type == 'weight':\n",
    "            row = random.randint(0,nn.weights[layer_index].shape[0]-1)\n",
    "            col = random.randint(0,nn.weights[layer_index].shape[1]-1)\n",
    "            point_index = (row, col)\n",
    "        elif type == 'bias':\n",
    "            point_index = random.randint(0,nn.biases[layer_index].size-1)\n",
    "        return (layer_index, point_index)\n",
    "\n",
    "    def get_all_scores(self):\n",
    "        return [net.score(self.X, self.y) for net in self.nets]\n",
    "\n",
    "    def get_all_accuracy(self):\n",
    "        return [net.accuracy(self.X, self.y) for net in self.nets]\n",
    "\n",
    "    def crossover(self, father, mother):\n",
    "\n",
    "        '''\n",
    "        @father = neural-net object representing father\n",
    "        @mother = neural-net object representing mother\n",
    "        @returns = new child based on father/mother genetic information\n",
    "        '''\n",
    "\n",
    "        # make a copy of father 'genetic' weights & biases information\n",
    "        nn = copy.deepcopy(father)\n",
    "\n",
    "        # cross-over bias\n",
    "        for _ in range(self.nets[0].bias_nitem):\n",
    "            # get some random points\n",
    "            layer, point = self.get_random_point('bias')\n",
    "            # replace genetic (bias) with mother's value\n",
    "            if random.uniform(0,1) < self.crossover_rate:\n",
    "                nn.biases[layer][point] = mother.biases[layer][point]\n",
    "\n",
    "        # cross-over weight\n",
    "        for _ in range(self.nets[0].weight_nitem):\n",
    "            # get some random points\n",
    "            layer, point = self.get_random_point('weight')\n",
    "            # replace genetic (weight) with mother's value\n",
    "            if random.uniform(0,1) < self.crossover_rate:\n",
    "                nn.weights[layer][point] = mother.weights[layer][point]\n",
    "        return nn\n",
    "        \n",
    "    def mutation(self, child):\n",
    "\n",
    "        '''\n",
    "        @child_index = neural-net object to mutate its internal weights & biases value\n",
    "        @returns = new mutated neural-net\n",
    "        '''\n",
    "\n",
    "        nn = copy.deepcopy(child)\n",
    "\n",
    "        # mutate bias\n",
    "        for _ in range(self.nets[0].bias_nitem):\n",
    "            # get some random points\n",
    "            layer, point = self.get_random_point('bias')\n",
    "            # add some random value between -0.5 and 0.5\n",
    "            if random.uniform(0,1) < self.mutation_rate:\n",
    "                nn.biases[layer][point] += random.uniform(-0.5, 0.5)\n",
    "\n",
    "        # mutate weight\n",
    "        for _ in range(self.nets[0].weight_nitem):\n",
    "            # get some random points\n",
    "            layer, point = self.get_random_point('weight')\n",
    "            # add some random value between -0.5 and 0.5\n",
    "            if random.uniform(0,1) < self.mutation_rate:\n",
    "                nn.weights[layer][point[0], point[1]] += random.uniform(-0.5, 0.5)\n",
    "\n",
    "        return nn\n",
    "\n",
    "    def evolve(self):\n",
    "\n",
    "        # calculate score for each population of neural-net\n",
    "        score_list = list(zip(self.nets, self.get_all_scores()))\n",
    "\n",
    "        # sort the network using its score\n",
    "        score_list.sort(key=lambda x: x[1])\n",
    "\n",
    "        # exclude score as it is not needed anymore\n",
    "        score_list = [obj[0] for obj in score_list]\n",
    "\n",
    "        # keep only the best one\n",
    "        retain_num = int(self.n_pops*self.retain_rate)\n",
    "        score_list_top = score_list[:retain_num]\n",
    "        # return some non-best ones\n",
    "        retain_non_best = int((self.n_pops-retain_num) * self.retain_rate)\n",
    "        for _ in range(random.randint(0, retain_non_best)):\n",
    "            score_list_top.append(random.choice(score_list[retain_num:]))\n",
    "        # breed new childs if current population number less than what we want\n",
    "        while len(score_list_top) < self.n_pops:\n",
    "\n",
    "            father = random.choice(score_list_top)\n",
    "            mother = random.choice(score_list_top)\n",
    "\n",
    "            if father != mother:\n",
    "                new_child = self.crossover(father, mother)\n",
    "                new_child = self.mutation(new_child)\n",
    "                score_list_top.append(new_child)\n",
    "        \n",
    "        # copy our new population to current object\n",
    "        self.nets = score_list_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    proc_data = data.drop(['PassengerId'], 1)\n",
    "\n",
    "    #rellenamos los valores vacios\n",
    "    proc_data['Age'].fillna(proc_data['Age'].mean(), inplace=True)\n",
    "    proc_data['Age'] = proc_data['Age'].astype(int)\n",
    "    proc_data['Fare'] = proc_data['Fare'].interpolate()\n",
    "    proc_data['Cabin'].fillna('U', inplace=True)\n",
    "\n",
    "    #normalizamos las columnas\n",
    "    proc_data['Title'] = pd.Series((name.split('.')[0].split(',')[1].strip() for name in data['Name']), index=data.index)\n",
    "    proc_data['Title'] = proc_data['Title'].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    proc_data['Title'] = proc_data['Title'].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\n",
    "\n",
    "    proc_data['Sex'] = proc_data['Sex'].map({'male': 0, 'female': 1})\n",
    "    proc_data['Embarked'] = proc_data['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "        #Creation of a deck column corresponding to the letter contained in the cabin value\n",
    "    proc_data['Cabin'] = proc_data['Cabin'].str[:1]\n",
    "    proc_data['Cabin'] = proc_data['Cabin'].map({cabin: p for p, cabin in enumerate(set(cab for cab in proc_data['Cabin']))})\n",
    "\n",
    "    proc_data = proc_data.drop(['Name', 'Ticket','Cabin','Title'], 1) \n",
    "\n",
    "    proc_data.dropna(axis =0, inplace=True)\n",
    "\n",
    "    return proc_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\helena.ridocci\\AppData\\Local\\Continuum\\anaconda3\\envs\\env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/helena.ridocci/Documents/Titanic'\n",
    "X_data = pd.read_csv(path+'/train.csv')\n",
    "X_val = pd.read_csv(path+'/test.csv')\n",
    "\n",
    "x_data =preprocess_data(X_data)\n",
    "x_val = preprocess_data(X_val)\n",
    "y_data = x_data.iloc[:,0]\n",
    "x_data = x_data.iloc[:,1:]\n",
    "X, x_test, y, y_test = train_test_split(x_data, y_data, test_size =0.2)\n",
    "y=y.values\n",
    "X = X.values\n",
    "    # convert y into one-hot encoded format\n",
    "y = y.reshape(-1, 1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(y)\n",
    "y = enc.transform(y).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration : 1\n",
      "Time taken by far : 0.0 seconds\n",
      "Current top member's network accuracy: 39.10%\n",
      "\n",
      "Current iteration : 11\n",
      "Time taken by far : 54.9 seconds\n",
      "Current top member's network accuracy: 60.90%\n",
      "\n",
      "Current iteration : 21\n",
      "Time taken by far : 115.0 seconds\n",
      "Current top member's network accuracy: 60.90%\n",
      "\n",
      "Current iteration : 31\n",
      "Time taken by far : 156.0 seconds\n",
      "Current top member's network accuracy: 60.90%\n",
      "\n",
      "Current iteration : 41\n",
      "Time taken by far : 209.4 seconds\n",
      "Current top member's network accuracy: 61.60%\n",
      "\n",
      "Current iteration : 51\n",
      "Time taken by far : 268.8 seconds\n",
      "Current top member's network accuracy: 61.18%\n",
      "\n",
      "Current iteration : 61\n",
      "Time taken by far : 325.6 seconds\n",
      "Current top member's network accuracy: 68.35%\n",
      "\n",
      "Current iteration : 71\n",
      "Time taken by far : 382.9 seconds\n",
      "Current top member's network accuracy: 67.65%\n",
      "\n",
      "Current iteration : 81\n",
      "Time taken by far : 444.3 seconds\n",
      "Current top member's network accuracy: 67.65%\n",
      "\n",
      "Current iteration : 91\n",
      "Time taken by far : 493.0 seconds\n",
      "Current top member's network accuracy: 67.51%\n",
      "\n",
      "Current iteration : 101\n",
      "Time taken by far : 545.9 seconds\n",
      "Current top member's network accuracy: 67.51%\n",
      "\n",
      "Current iteration : 111\n",
      "Time taken by far : 618.7 seconds\n",
      "Current top member's network accuracy: 67.51%\n",
      "\n",
      "Current iteration : 121\n",
      "Time taken by far : 677.8 seconds\n",
      "Current top member's network accuracy: 67.51%\n",
      "\n",
      "Current iteration : 131\n",
      "Time taken by far : 725.5 seconds\n",
      "Current top member's network accuracy: 67.51%\n",
      "\n",
      "Current iteration : 141\n",
      "Time taken by far : 785.8 seconds\n",
      "Current top member's network accuracy: 67.51%\n",
      "\n",
      "Current iteration : 151\n",
      "Time taken by far : 845.9 seconds\n",
      "Current top member's network accuracy: 67.51%\n",
      "\n",
      "Current iteration : 161\n",
      "Time taken by far : 888.8 seconds\n",
      "Current top member's network accuracy: 67.79%\n",
      "\n",
      "Current iteration : 171\n",
      "Time taken by far : 941.4 seconds\n",
      "Current top member's network accuracy: 72.15%\n",
      "\n",
      "Current iteration : 181\n",
      "Time taken by far : 994.3 seconds\n",
      "Current top member's network accuracy: 72.15%\n",
      "\n",
      "Current iteration : 191\n",
      "Time taken by far : 1045.1 seconds\n",
      "Current top member's network accuracy: 72.15%\n",
      "\n",
      "Current iteration : 201\n",
      "Time taken by far : 1068.6 seconds\n",
      "Current top member's network accuracy: 72.15%\n",
      "\n",
      "Current iteration : 211\n",
      "Time taken by far : 1089.8 seconds\n",
      "Current top member's network accuracy: 72.15%\n",
      "\n",
      "Current iteration : 221\n",
      "Time taken by far : 1121.7 seconds\n",
      "Current top member's network accuracy: 75.67%\n",
      "\n",
      "Current iteration : 231\n",
      "Time taken by far : 1182.9 seconds\n",
      "Current top member's network accuracy: 75.67%\n",
      "\n",
      "Current iteration : 241\n",
      "Time taken by far : 1247.0 seconds\n",
      "Current top member's network accuracy: 73.98%\n",
      "\n",
      "Current iteration : 251\n",
      "Time taken by far : 1302.1 seconds\n",
      "Current top member's network accuracy: 77.92%\n",
      "\n",
      "Current iteration : 261\n",
      "Time taken by far : 1356.2 seconds\n",
      "Current top member's network accuracy: 78.90%\n",
      "\n",
      "Current iteration : 271\n",
      "Time taken by far : 1411.8 seconds\n",
      "Current top member's network accuracy: 78.90%\n",
      "\n",
      "Current iteration : 281\n",
      "Time taken by far : 1468.4 seconds\n",
      "Current top member's network accuracy: 78.90%\n",
      "\n",
      "Current iteration : 291\n",
      "Time taken by far : 1505.4 seconds\n",
      "Current top member's network accuracy: 79.47%\n",
      "\n",
      "Current iteration : 301\n",
      "Time taken by far : 1561.8 seconds\n",
      "Current top member's network accuracy: 78.76%\n",
      "\n",
      "Current iteration : 311\n",
      "Time taken by far : 1618.7 seconds\n",
      "Current top member's network accuracy: 80.31%\n",
      "\n",
      "Current iteration : 321\n",
      "Time taken by far : 1654.6 seconds\n",
      "Current top member's network accuracy: 79.89%\n",
      "\n",
      "Current iteration : 331\n",
      "Time taken by far : 1697.6 seconds\n",
      "Current top member's network accuracy: 79.89%\n",
      "\n",
      "Current iteration : 341\n",
      "Time taken by far : 1751.5 seconds\n",
      "Current top member's network accuracy: 81.01%\n",
      "\n",
      "Current iteration : 351\n",
      "Time taken by far : 1805.7 seconds\n",
      "Current top member's network accuracy: 81.29%\n",
      "\n",
      "Current iteration : 361\n",
      "Time taken by far : 1847.5 seconds\n",
      "Current top member's network accuracy: 81.29%\n",
      "\n",
      "Current iteration : 371\n",
      "Time taken by far : 1906.3 seconds\n",
      "Current top member's network accuracy: 81.15%\n",
      "\n",
      "Current iteration : 381\n",
      "Time taken by far : 1964.0 seconds\n",
      "Current top member's network accuracy: 81.15%\n",
      "\n",
      "Current iteration : 391\n",
      "Time taken by far : 2028.0 seconds\n",
      "Current top member's network accuracy: 80.45%\n",
      "\n",
      "Current iteration : 401\n",
      "Time taken by far : 2060.6 seconds\n",
      "Current top member's network accuracy: 80.45%\n",
      "\n",
      "Current iteration : 411\n",
      "Time taken by far : 2113.8 seconds\n",
      "Current top member's network accuracy: 80.87%\n",
      "\n",
      "Current iteration : 421\n",
      "Time taken by far : 2171.5 seconds\n",
      "Current top member's network accuracy: 80.87%\n",
      "\n",
      "Current iteration : 431\n",
      "Time taken by far : 2225.2 seconds\n",
      "Current top member's network accuracy: 80.03%\n",
      "\n",
      "Current iteration : 441\n",
      "Time taken by far : 2249.4 seconds\n",
      "Current top member's network accuracy: 80.87%\n",
      "\n",
      "Current iteration : 451\n",
      "Time taken by far : 2296.3 seconds\n",
      "Current top member's network accuracy: 80.87%\n",
      "\n",
      "Current iteration : 461\n",
      "Time taken by far : 2367.9 seconds\n",
      "Current top member's network accuracy: 81.15%\n",
      "\n",
      "Current iteration : 471\n",
      "Time taken by far : 2427.2 seconds\n",
      "Current top member's network accuracy: 81.15%\n",
      "\n",
      "Current iteration : 481\n",
      "Time taken by far : 2489.4 seconds\n",
      "Current top member's network accuracy: 81.43%\n",
      "\n",
      "Current iteration : 491\n",
      "Time taken by far : 2568.4 seconds\n",
      "Current top member's network accuracy: 81.43%\n",
      "\n",
      "Current iteration : 501\n",
      "Time taken by far : 2653.5 seconds\n",
      "Current top member's network accuracy: 82.14%\n",
      "\n",
      "Current iteration : 511\n",
      "Time taken by far : 2708.6 seconds\n",
      "Current top member's network accuracy: 82.14%\n",
      "\n",
      "Current iteration : 521\n",
      "Time taken by far : 2785.0 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 531\n",
      "Time taken by far : 2851.5 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 541\n",
      "Time taken by far : 2879.0 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 551\n",
      "Time taken by far : 2932.3 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 561\n",
      "Time taken by far : 2988.7 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 571\n",
      "Time taken by far : 3043.7 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 581\n",
      "Time taken by far : 3091.8 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 591\n",
      "Time taken by far : 3152.5 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 601\n",
      "Time taken by far : 3210.8 seconds\n",
      "Current top member's network accuracy: 82.42%\n",
      "\n",
      "Current iteration : 611\n",
      "Time taken by far : 3261.5 seconds\n",
      "Current top member's network accuracy: 82.42%\n",
      "\n",
      "Current iteration : 621\n",
      "Time taken by far : 3321.9 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 631\n",
      "Time taken by far : 3380.6 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 641\n",
      "Time taken by far : 3429.3 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 651\n",
      "Time taken by far : 3485.0 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 661\n",
      "Time taken by far : 3546.1 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 671\n",
      "Time taken by far : 3604.3 seconds\n",
      "Current top member's network accuracy: 82.14%\n",
      "\n",
      "Current iteration : 681\n",
      "Time taken by far : 3646.8 seconds\n",
      "Current top member's network accuracy: 82.14%\n",
      "\n",
      "Current iteration : 691\n",
      "Time taken by far : 3704.9 seconds\n",
      "Current top member's network accuracy: 82.14%\n",
      "\n",
      "Current iteration : 701\n",
      "Time taken by far : 3761.4 seconds\n",
      "Current top member's network accuracy: 82.14%\n",
      "\n",
      "Current iteration : 711\n",
      "Time taken by far : 3806.4 seconds\n",
      "Current top member's network accuracy: 82.14%\n",
      "\n",
      "Current iteration : 721\n",
      "Time taken by far : 3858.9 seconds\n",
      "Current top member's network accuracy: 82.14%\n",
      "\n",
      "Current iteration : 731\n",
      "Time taken by far : 3916.8 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 741\n",
      "Time taken by far : 3977.6 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 751\n",
      "Time taken by far : 4024.9 seconds\n",
      "Current top member's network accuracy: 82.56%\n",
      "\n",
      "Current iteration : 761\n",
      "Time taken by far : 4079.8 seconds\n",
      "Current top member's network accuracy: 82.56%\n",
      "\n",
      "Current iteration : 771\n",
      "Time taken by far : 4140.2 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 781\n",
      "Time taken by far : 4183.2 seconds\n",
      "Current top member's network accuracy: 82.28%\n",
      "\n",
      "Current iteration : 791\n",
      "Time taken by far : 4219.2 seconds\n",
      "Current top member's network accuracy: 82.42%\n",
      "\n",
      "Current iteration : 801\n",
      "Time taken by far : 4283.9 seconds\n",
      "Current top member's network accuracy: 82.42%\n",
      "\n",
      "Current iteration : 811\n",
      "Time taken by far : 4356.0 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 821\n",
      "Time taken by far : 4405.8 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 831\n",
      "Time taken by far : 4444.5 seconds\n",
      "Current top member's network accuracy: 82.56%\n",
      "\n",
      "Current iteration : 841\n",
      "Time taken by far : 4499.4 seconds\n",
      "Current top member's network accuracy: 82.56%\n",
      "\n",
      "Current iteration : 851\n",
      "Time taken by far : 4555.1 seconds\n",
      "Current top member's network accuracy: 82.56%\n",
      "\n",
      "Current iteration : 861\n",
      "Time taken by far : 4614.7 seconds\n",
      "Current top member's network accuracy: 82.56%\n",
      "\n",
      "Current iteration : 871\n",
      "Time taken by far : 4648.7 seconds\n",
      "Current top member's network accuracy: 82.56%\n",
      "\n",
      "Current iteration : 881\n",
      "Time taken by far : 4698.6 seconds\n",
      "Current top member's network accuracy: 82.56%\n",
      "\n",
      "Current iteration : 891\n",
      "Time taken by far : 4763.3 seconds\n",
      "Current top member's network accuracy: 82.84%\n",
      "\n",
      "Current iteration : 901\n",
      "Time taken by far : 4826.4 seconds\n",
      "Current top member's network accuracy: 83.26%\n",
      "\n",
      "Current iteration : 911\n",
      "Time taken by far : 4858.8 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 921\n",
      "Time taken by far : 4907.8 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 931\n",
      "Time taken by far : 4960.3 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 941\n",
      "Time taken by far : 5011.7 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 951\n",
      "Time taken by far : 5038.2 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 961\n",
      "Time taken by far : 5083.6 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 971\n",
      "Time taken by far : 5136.9 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 981\n",
      "Time taken by far : 5193.3 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n",
      "Current iteration : 991\n",
      "Time taken by far : 5218.7 seconds\n",
      "Current top member's network accuracy: 82.98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "    # parameters\n",
    "N_POPS = 100\n",
    "NET_SIZE = [7,6,5,2]\n",
    "MUTATION_RATE = 0.2\n",
    "CROSSOVER_RATE = 0.6\n",
    "RETAIN_RATE = 0.6\n",
    "\n",
    "    # start our neural-net & optimize it using genetic algorithm\n",
    "nnga = NNGeneticAlgo(N_POPS, NET_SIZE, MUTATION_RATE, CROSSOVER_RATE, RETAIN_RATE, X, y)\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "    # run for n iterations\n",
    "for i in range(1000):\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(\"Current iteration : {}\".format(i+1))\n",
    "        print(\"Time taken by far : %.1f seconds\" % (time.time() - start_time))\n",
    "        print(\"Current top member's network accuracy: %.2f%%\\n\" % nnga.get_all_accuracy()[0])\n",
    "\n",
    "        # evolve the population\n",
    "    nnga.evolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "num_cpu = multiprocessing.cpu_count()\n",
    "num_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
